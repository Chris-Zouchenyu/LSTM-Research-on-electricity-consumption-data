### LSTM-Research-on-electricity-consumption-data
This is a project that uses electricity consumption datasets to study LSTM!  
Happy Chinese New Year!:)  
We all know that LSTM is very effective in processing temporal logic data, which is why it is widely used in fields such as speech recognition and language translation. However, how to efficiently use this algorithm is a headache for many beginners in the AI field, including myself. Therefore, in this project, we will conduct research on temporal logic algorithms from shallow to deep, including naive model algorithms (simple model algorithms), CNN, CNN-LSTM (which I am currently studying), attention mechanisms, etc. The data used comes from  
https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption  
The data contains 2075259 measurements gathered in a house located in Sceaux (7km of Paris, France) between December 2006 and November 2010 (47 months).   
More about the data  
1.(global_active_power*1000/60 - sub_metering_1 - sub_metering_2 - sub_metering_3) represents the active energy consumed every minute (in watt hour) in the household by electrical equipment not measured in sub-meterings 1, 2 and 3.  
2.The dataset contains some missing values in the measurements (nearly 1,25% of the rows). All calendar timestamps are present in the dataset but for some timestamps, the measurement values are missing: a missing value is represented by the absence of value between two consecutive semi-colon attribute separators. 

In this project, I analysis electricity consumption data using seven models.The RMSE of each models are over here.  
![image](https://github.com/Chris-Zouchenyu/LSTM-Research-on-electricity-consumption-data/blob/main/picture/table.png)  
Among these models, in addition to traditional models such as LSTM, CNN, and BPNN, I added CNN-LSTM-new and MCNN models. It can be seen that for traditional models, on this dataset, the CNN model does not perform well, and its RMSE is even higher than that of naive models. On the one hand, this may be due to insufficient training times, and on the other hand, it may be because individual CNN models perform poorly in feature extraction for data that relies on temporal logic. On the contrary, for traditional models with strong temporal logic data processing capabilities, LSTM performs exceptionally well. For the fusion model, the CNN-LSTM new model inherits both the excellent feature extraction ability of the CNN model and the excellent temporal data processing ability of the LSTM model, with the lowest RMSE on this dataset. However, not all fusion models perform well, such as the CNN-LSTM model. Due to a lack of experience in model building, I used the Conv2D function in Pytorch to extract features from the data in the early stages of model construction, and did not flatten the original data when connecting the LSTM layer. This makes the model's prediction performance far inferior to the LSTM model. However, when using the Conv1D function and connecting the flattened data to the LSTM layer, the model performs well, which is the origin of the CNN-LSTM-new model.

In the model prediction section, I used the trained model to predict the total electricity data on the test set on a weekly basis, and the prediction results are shown in the following figure.  
![image]()
